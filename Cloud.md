# Cloud Architecture Guide: LegalAI Document Demystifier

This document provides a detailed explanation of the Google Cloud services and architectural patterns used in the LegalAI Document Demystifier project.

## 1. Core Architectural Principles

The project is built on a serverless, multi-agent architecture designed for scalability, modularity, and cost-efficiency.

* **Serverless:** The entire backend runs on **Google Cloud Functions**, which means there are no servers to manage. The system automatically scales based on the number of documents being uploaded and you only pay for the compute time you use.

* **Multi-Agent System:** The complex task of analyzing a document is broken down into smaller, independent "agents." Each agent is a Cloud Function with a single, specialized responsibility. This makes the system easier to develop, debug, and upgrade.

* **Event-Driven Choreography:** The pipeline is initiated by an event (a file upload). The first agent processes the file and then directly calls the main orchestrator via an HTTP request. The orchestrator then calls the other analysis agents. This creates a robust and loosely-coupled workflow.

---

## 2. Detailed Component Breakdown

### Compute

* #### Cloud Functions (2nd Gen)
    The core of the backend, where each agent's Python code is executed. As 2nd Gen functions, they run on top of Cloud Run, providing enhanced performance and configuration options.
    * **`document-agent`**: The entry point. Triggered by uploads to Cloud Storage, it performs OCR and starts the pipeline.
    * **`constitutional-agent`**: The legal analysis brain. It uses the Gemini LLM to check for compliance issues.
    * **`web-intelligence-agent`**: The research paralegal. It searches the web for relevant precedents.
    * **`visualization-agent`**: The data artist. It generates a visual summary report of the findings.
    * **`ai-orchestrator`**: The project manager. It coordinates the calls to the analysis and visualization agents.

---

### Storage & Database

* #### Cloud Storage
    This service plays two critical roles:
    1.  **Ingestion Point:** It's the landing zone for user-uploaded PDF documents. A file upload to this bucket is the event that kicks off the entire process.
    2.  **Artifact Repository:** It stores the final output images (the PNG "Report Cards") generated by the `visualization-agent`.

* #### Firestore
    This is the central "state machine" and database for the project. It's a NoSQL document database where a record is created for each uploaded file. As the agents run, they read from and write their results back to the corresponding Firestore document, progressively enriching it with data.

---

### AI & Machine Learning

* #### Document AI
    This service acts as the powerful OCR engine. We use a pre-trained **"Document OCR" processor** that takes a PDF file as input and intelligently extracts all of its text content, which is the foundational data for all subsequent analysis.

* #### Vertex AI - Gemini Models
    This is the project's core intelligence, providing Large Language Model (LLM) capabilities. We use the **`gemini-2.5-flash`** model in two distinct ways:
    1.  **Complex Reasoning (`constitutional-agent`):** It analyzes the full document text based on a detailed prompt and returns a structured JSON object containing its legal analysis.
    2.  **Query Generation (`web-intelligence-agent`):** It performs a simpler task of reading the document text and summarizing it into a concise search query to be used by another service.

* #### Vertex AI Search
    This service functions as our project's private, specialized search engine. We created a **Data Store** by providing it with a curated list of public Indian legal websites. The `web-intelligence-agent` uses the Gemini-generated query to search *only* this data store, ensuring that the results are highly relevant and come from authoritative sources.

---

### Security & Identity

* #### Identity and Access Management (IAM)
    IAM is used to control which users and services have permission to do what. We follow the principle of least privilege.

* #### Service Accounts
    Instead of using the default identity, we created a dedicated **`function-runner-sa`** service account. This non-human identity is assigned to our functions, and we grant it a specific set of roles (`Datastore User`, `Storage Object Admin`, `Service Account Token Creator`) so it has just enough permission to do its job and no more. This is a critical security best practice.

---

### Networking & Triggers

* #### Eventarc
    This is the underlying service that manages the trigger for our initial `document-agent`. It listens for the `google.cloud.storage.object.v1.finalized` event and invokes the function.

* #### Cloud Run URLs
    Because we use 2nd Gen Cloud Functions, they are each deployed as a Cloud Run service with a stable HTTPS endpoint (ending in `.a.run.app`). These URLs are used for the secure, authenticated, function-to-function communication in our pipeline, for example, when the `document-agent` calls the `ai-orchestrator`.
